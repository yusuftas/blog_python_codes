{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post, I will go over tensorflow OpenCV object detection module. To be honest, I haven't used OpenCV for quite some time. And after recently looking into it, I have realized how awesome OpenCV has become. It <b>now has a dedicated DNN (deep neural network) module</b>. This module also has <b>functionality to load Caffe and Tensorflow trained networks.</b> I am just so happy to see that functionality in OpenCV. Just think about it, you can use your trained networks within OpenCV.\n",
    "\n",
    "Alright, enough blabbering, let's get to the point. So in this post, I will use tensorflow detection module to load a trained tensorflow network and use this network to apply object detection to a webcam stream. So in the end, we will have a display that shows webcam stream and in the stream we modify the frames and display detected objects with rectangles. \n",
    "\n",
    "Alright, first thing is to get camera stream and display it. Later on we will expand this code to apply object detection to each frame instead of just displaying. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import sys\n",
    "\n",
    "#print(sys.executable)\n",
    "#print(sys.path)\n",
    "\n",
    "#sys.path.append('/home/yutas/anaconda2/envs/testcaffe/lib/python2.7/site-packages/')\n",
    "\n",
    "import cv2 as cv\n",
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.1) /feedstock_root/build_artefacts/opencv_1520722613778/work/opencv-3.4.1/modules/highgui/src/window.cpp:356: error: (-215) size.width>0 && size.height>0 in function imshow\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c6e4e3352a15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mret_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my webcam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m27\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.1) /feedstock_root/build_artefacts/opencv_1520722613778/work/opencv-3.4.1/modules/highgui/src/window.cpp:356: error: (-215) size.width>0 && size.height>0 in function imshow\n"
     ]
    }
   ],
   "source": [
    "cam = cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret_val, img = cam.read()\n",
    "\n",
    "    cv.imshow('my webcam', img)\n",
    "\n",
    "    if cv.waitKey(1) == 27: \n",
    "        break  # esc to quit\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we got the webcam stream working, next step is to integrate this with object detection. For object detection, I will use one of the networks available in Tensorflow Object detection module website : <a href='https://github.com/opencv/opencv/wiki/TensorFlow-Object-Detection-API'> Tensorflow Object Detection API</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cam = cv.VideoCapture(0)\n",
    "cvNet = cv.dnn.readNetFromTensorflow('./mobilenet.pb', 'mobilenet.pbtxt')\n",
    "\n",
    "while True:\n",
    "    ret_val, img = cam.read()\n",
    "\n",
    "    rows = img.shape[0]\n",
    "    cols = img.shape[1]\n",
    "    cvNet.setInput(cv.dnn.blobFromImage(img, 1.0/127.5, (300, 300), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
    "    cvOut = cvNet.forward()\n",
    "\n",
    "    for detection in cvOut[0,0,:,:]:\n",
    "        score = float(detection[2])\n",
    "        if score > 0.3:\n",
    "            left = detection[3] * cols\n",
    "            top = detection[4] * rows\n",
    "            right = detection[5] * cols\n",
    "            bottom = detection[6] * rows\n",
    "            cv.rectangle(img, (int(left), int(top)), (int(right), int(bottom)), (23, 230, 210), thickness=2)\n",
    "\n",
    "    cv.imshow('my webcam', img)\n",
    "\n",
    "    if cv.waitKey(1) == 27: \n",
    "        break  # esc to quit\n",
    "\n",
    "cam.release()\n",
    "cv.destroyAllWindows()        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (testcaffe)",
   "language": "python",
   "name": "testcaffe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
